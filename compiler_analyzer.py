"""
Ù…Ø­Ù„Ù„ Ù…Ø±Ø§Ø­Ù„ Ø§Ù„ØªØ±Ø¬Ù…Ø© - Compiler Stages Analyzer
ÙŠØ­Ø³Ø¨ Ù…Ø®Ø±Ø¬Ø§Øª ÙƒÙ„ Ù…Ø±Ø­Ù„Ø© Ù…Ù† Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ù…ØªØ±Ø¬Ù… Ø¨Ø´ÙƒÙ„ ÙØ¹Ù„ÙŠ
"""

from antlr4 import InputStream, CommonTokenStream
from ArabicGrammarLexer import ArabicGrammarLexer
from ArabicGrammarParser import ArabicGrammarParser
from semantic_analyzer import SemanticAnalyzer
from code_generator import CodeGenerator
import ast_nodes


class CompilerAnalyzer:
    """Ù…Ø­Ù„Ù„ Ù…Ø±Ø§Ø­Ù„ Ø§Ù„ØªØ±Ø¬Ù…Ø©"""
    
    def __init__(self):
        self.lexer = None
        self.tokens = None
        self.parser = None
        self.tree = None
        self.analyzer = None
        self.ast = None
        self.generator = None
        self.python_code = None
        self.errors = []
    
    def analyze_lexical(self, source_code):
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø¬Ù…ÙŠ - Lexical Analysis"""
        try:
            input_stream = InputStream(source_code)
            self.lexer = ArabicGrammarLexer(input_stream)
            token_stream = CommonTokenStream(self.lexer)
            token_stream.fill()
            self.tokens = token_stream.tokens
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ù…ÙˆØ²
            result = {
                'success': True,
                'tokens': [],
                'token_count': len(self.tokens)
            }
            
            for token in self.tokens:
                if token.type != -1:  # ØªØ¬Ø§Ù‡Ù„ EOF
                    token_info = {
                        'type': self.lexer.symbolicNames[token.type] if token.type < len(self.lexer.symbolicNames) else 'UNKNOWN',
                        'text': token.text,
                        'line': token.line,
                        'column': token.column
                    }
                    result['tokens'].append(token_info)
            
            return result
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'tokens': []
            }
    
    def analyze_syntax(self, source_code):
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ - Syntax Analysis"""
        try:
            input_stream = InputStream(source_code)
            lexer = ArabicGrammarLexer(input_stream)
            token_stream = CommonTokenStream(lexer)
            self.parser = ArabicGrammarParser(token_stream)
            
            # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø´Ø¬Ø±Ø©
            self.tree = self.parser.program()
            
            # ÙØ­Øµ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù†Ø­ÙˆÙŠØ©
            syntax_errors = self.parser.getNumberOfSyntaxErrors()
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø´Ø¬Ø±Ø© Ø¥Ù„Ù‰ Ø´ÙƒÙ„ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©
            tree_structure = self.format_parse_tree(self.tree, self.parser)
            
            result = {
                'success': syntax_errors == 0,
                'tree_raw': self.tree.toStringTree(recog=self.parser) if self.tree else None,
                'tree_formatted': tree_structure,
                'error_count': syntax_errors,
                'errors': []
            }
            
            return result
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'tree_raw': None,
                'tree_formatted': []
            }
    
    def format_parse_tree(self, tree, parser, indent=0):
        """ØªÙ†Ø³ÙŠÙ‚ Ø´Ø¬Ø±Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ Ø¨Ø´ÙƒÙ„ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©"""
        formatted_lines = []
        indent_str = "  " * indent
        
        if tree is None:
            return formatted_lines
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©
        rule_name = parser.ruleNames[tree.getRuleIndex()] if hasattr(tree, 'getRuleIndex') else 'Terminal'
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¹Ù‚Ø¯Ø© Ù†Ù‡Ø§Ø¦ÙŠØ© (Terminal)
        if hasattr(tree, 'symbol'):
            token_text = tree.getText()
            formatted_lines.append(f"{indent_str}â””â”€ ğŸ“ {token_text}")
        else:
            # Ø¹Ù‚Ø¯Ø© ØºÙŠØ± Ù†Ù‡Ø§Ø¦ÙŠØ© (Non-terminal)
            formatted_lines.append(f"{indent_str}â”œâ”€ ğŸ”· {rule_name}")
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø¨Ù†Ø§Ø¡
            if hasattr(tree, 'children') and tree.children:
                for i, child in enumerate(tree.children):
                    is_last = (i == len(tree.children) - 1)
                    child_lines = self.format_parse_tree(child, parser, indent + 1)
                    formatted_lines.extend(child_lines)
        
        return formatted_lines
    
    def analyze_semantic(self, source_code):
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ - Semantic Analysis Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ Ø´Ø§Ù…Ù„Ø©"""
        try:
            # Ø£ÙˆÙ„Ø§Ù‹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ
            input_stream = InputStream(source_code)
            lexer = ArabicGrammarLexer(input_stream)
            token_stream = CommonTokenStream(lexer)
            parser = ArabicGrammarParser(token_stream)
            tree = parser.program()
            
            # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
            self.analyzer = SemanticAnalyzer()
            self.ast = self.analyzer.visit(tree)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ÙƒØ§Ù…Ù„
            symbol_table_data = self.get_symbol_table_data()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¬Ø±Ø© AST Ø§Ù„Ù…Ù†Ø³Ù‚Ø©
            ast_formatted = self.format_ast_tree(self.ast)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©
            semantic_errors = self.format_semantic_errors(self.analyzer.errors)
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
            statistics = self.get_semantic_statistics(symbol_table_data, self.analyzer.errors)
            
            result = {
                'success': len(self.analyzer.errors) == 0,
                'ast': self.ast,
                'ast_formatted': ast_formatted,
                'errors': [str(err) for err in self.analyzer.errors],
                'errors_formatted': semantic_errors,
                'symbol_table': symbol_table_data,
                'statistics': statistics
            }
            
            return result
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'ast': None,
                'ast_formatted': [],
                'errors': [str(e)],
                'errors_formatted': [],
                'symbol_table': [],
                'statistics': {}
            }
    
    def format_ast_tree(self, node, indent=0, prefix=""):
        """ØªÙ†Ø³ÙŠÙ‚ Ø´Ø¬Ø±Ø© AST Ø¨Ø´ÙƒÙ„ Ù‡Ø±Ù…ÙŠ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©"""
        lines = []
        indent_str = "  " * indent
        
        if node is None:
            return lines
        
        # Ø§Ø³Ù… Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø¯Ø©
        node_type = node.__class__.__name__
        
        # Ø±Ù…Ø² Ø§Ù„Ø¹Ù‚Ø¯Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        icon = self.get_node_icon(node_type)
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø¹Ù† Ø§Ù„Ø¹Ù‚Ø¯Ø©
        node_info = self.get_node_info(node)
        
        # Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ø¹Ù‚Ø¯Ø©
        if node_info:
            lines.append(f"{indent_str}{prefix}{icon} {node_type}: {node_info}")
        else:
            lines.append(f"{indent_str}{prefix}{icon} {node_type}")
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø·ÙØ§Ù„
        children = self.get_node_children(node)
        for i, (child_name, child_node) in enumerate(children):
            is_last = (i == len(children) - 1)
            child_prefix = "â””â”€ " if is_last else "â”œâ”€ "
            
            if isinstance(child_node, list):
                # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø·ÙÙ„ Ù‚Ø§Ø¦Ù…Ø©
                lines.append(f"{indent_str}  {child_prefix}ğŸ“‹ {child_name} [{len(child_node)} Ø¹Ù†ØµØ±]")
                for j, item in enumerate(child_node):
                    item_is_last = (j == len(child_node) - 1)
                    item_prefix = "   â””â”€ " if item_is_last else "   â”œâ”€ "
                    item_lines = self.format_ast_tree(item, indent + 2, item_prefix)
                    lines.extend(item_lines)
            elif child_node is not None:
                # Ø·ÙÙ„ ÙˆØ§Ø­Ø¯
                child_lines = self.format_ast_tree(child_node, indent + 1, child_prefix)
                lines.extend(child_lines)
        
        return lines
    
    def get_node_icon(self, node_type):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙŠÙ‚ÙˆÙ†Ø© Ù…Ù†Ø§Ø³Ø¨Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø¯Ø©"""
        icon_map = {
            'ProgramNode': 'ğŸ¯',
            'BlockNode': 'ğŸ“¦',
            'ConstantDefNode': 'ğŸ”’',
            'VarDeclNode': 'ğŸ“Š',
            'ProcedureDefNode': 'âš™ï¸',
            'AssignmentNode': 'â¡ï¸',
            'InputNode': 'âŒ¨ï¸',
            'OutputNode': 'ğŸ–¨ï¸',
            'IfNode': 'â“',
            'ForLoopNode': 'ğŸ”„',
            'WhileLoopNode': 'ğŸ”',
            'CallNode': 'ğŸ“',
            'BinOpNode': 'â•',
            'UnaryOpNode': 'â–',
            'VarAccessNode': 'ğŸ“Œ',
            'LiteralNode': 'ğŸ’',
            'CompoundStmtNode': 'ğŸ“',
        }
        return icon_map.get(node_type, 'ğŸ”¸')
    
    def get_node_info(self, node):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø¹Ù† Ø§Ù„Ø¹Ù‚Ø¯Ø©"""
        info_parts = []
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø¯Ø©
        if hasattr(node, 'name'):
            info_parts.append(f"'{node.name}'")
        
        if hasattr(node, 'value') and node.value is not None:
            if isinstance(node.value, str):
                info_parts.append(f"Ø§Ù„Ù‚ÙŠÙ…Ø©: '{node.value}'")
            else:
                info_parts.append(f"Ø§Ù„Ù‚ÙŠÙ…Ø©: {node.value}")
        
        if hasattr(node, 'operator'):
            info_parts.append(f"Ø§Ù„Ø¹Ø§Ù…Ù„: {node.operator}")
        
        if hasattr(node, 'data_type') and node.data_type:
            info_parts.append(f"Ø§Ù„Ù†ÙˆØ¹: {node.data_type}")
        
        if hasattr(node, 'literal_type') and node.literal_type:
            info_parts.append(f"Ø§Ù„Ù†ÙˆØ¹: {node.literal_type}")
        
        return " | ".join(info_parts) if info_parts else ""
    
    def get_node_children(self, node):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø·ÙØ§Ù„ Ø§Ù„Ø¹Ù‚Ø¯Ø©"""
        children = []
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ù‡Ù…Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù‚Ø¯Ø©
        if hasattr(node, 'block') and node.block:
            children.append(('block', node.block))
        
        if hasattr(node, 'constants') and node.constants:
            children.append(('constants', node.constants))
        
        if hasattr(node, 'variables') and node.variables:
            children.append(('variables', node.variables))
        
        if hasattr(node, 'procedures') and node.procedures:
            children.append(('procedures', node.procedures))
        
        if hasattr(node, 'instructions') and node.instructions:
            children.append(('instructions', node.instructions))
        
        if hasattr(node, 'statements') and node.statements:
            children.append(('statements', node.statements))
        
        if hasattr(node, 'variable') and node.variable:
            children.append(('variable', node.variable))
        
        if hasattr(node, 'expression') and node.expression:
            children.append(('expression', node.expression))
        
        if hasattr(node, 'condition') and node.condition:
            children.append(('condition', node.condition))
        
        if hasattr(node, 'then_stmt') and node.then_stmt:
            children.append(('then_stmt', node.then_stmt))
        
        if hasattr(node, 'else_stmt') and node.else_stmt:
            children.append(('else_stmt', node.else_stmt))
        
        if hasattr(node, 'body') and node.body:
            children.append(('body', node.body))
        
        if hasattr(node, 'left') and node.left:
            children.append(('left', node.left))
        
        if hasattr(node, 'right') and node.right:
            children.append(('right', node.right))
        
        if hasattr(node, 'operand') and node.operand:
            children.append(('operand', node.operand))
        
        if hasattr(node, 'items') and node.items:
            children.append(('items', node.items))
        
        if hasattr(node, 'arguments') and node.arguments:
            children.append(('arguments', node.arguments))
        
        return children
    
    def format_semantic_errors(self, errors):
        """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© Ù…Ø¹ ØªÙØ§ØµÙŠÙ„"""
        formatted_errors = []
        
        for i, error in enumerate(errors, 1):
            error_info = {
                'number': i,
                'message': str(error),
                'line': None,
                'column': None,
                'severity': 'Ø®Ø·Ø£'
            }
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„Ø³Ø·Ø± ÙˆØ§Ù„Ø¹Ù…ÙˆØ¯ Ø¥Ù† ÙˆØ¬Ø¯
            if hasattr(error, 'line'):
                error_info['line'] = error.line
            if hasattr(error, 'column'):
                error_info['column'] = error.column
            
            # ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£
            error_msg = str(error).lower()
            if 'type' in error_msg or 'Ù†ÙˆØ¹' in error_msg:
                error_info['type'] = 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹'
            elif 'undefined' in error_msg or 'ØºÙŠØ± Ù…Ø¹Ø±Ù‘Ù' in error_msg:
                error_info['type'] = 'Ø±Ù…Ø² ØºÙŠØ± Ù…Ø¹Ø±Ù‘Ù'
            elif 'scope' in error_msg or 'Ù†Ø·Ø§Ù‚' in error_msg:
                error_info['type'] = 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø·Ø§Ù‚'
            else:
                error_info['type'] = 'Ø®Ø·Ø£ Ø¯Ù„Ø§Ù„ÙŠ Ø¹Ø§Ù…'
            
            formatted_errors.append(error_info)
        
        return formatted_errors
    
    def get_semantic_statistics(self, symbol_table, errors):
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ"""
        stats = {
            'total_symbols': len(symbol_table),
            'total_errors': len(errors),
            'variables': 0,
            'constants': 0,
            'procedures': 0,
            'parameters': 0,
            'types': 0
        }
        
        for symbol in symbol_table:
            sym_type = symbol.get('type', '').upper()
            if 'VARIABLE' in sym_type:
                stats['variables'] += 1
            elif 'CONSTANT' in sym_type:
                stats['constants'] += 1
            elif 'PROCEDURE' in sym_type:
                stats['procedures'] += 1
            elif 'PARAMETER' in sym_type:
                stats['parameters'] += 1
            elif 'TYPE' in sym_type:
                stats['types'] += 1
        
        return stats
    
    def get_symbol_table_data(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø±Ù…ÙˆØ² - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª"""
        if not self.analyzer:
            return []
        
        symbols = []
        
        try:
            # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø±Ù…ÙˆØ² Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù„Ù‡ Ù‡ÙŠÙƒÙ„ Ù…Ø®ØªÙ„Ù
            symbol_table = self.analyzer.symbol_table
            
            # Ø·Ø±ÙŠÙ‚Ø© 1: Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ attribute Ø§Ø³Ù…Ù‡ scopes (Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª)
            if hasattr(symbol_table, 'scopes'):
                for scope_level, scope in enumerate(symbol_table.scopes):
                    if isinstance(scope, dict):
                        for name, symbol in scope.items():
                            symbols.append(self.extract_symbol_info(symbol, scope_level))
            
            # Ø·Ø±ÙŠÙ‚Ø© 2: Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ attribute Ø§Ø³Ù…Ù‡ current_scope
            elif hasattr(symbol_table, 'current_scope') and symbol_table.current_scope:
                if isinstance(symbol_table.current_scope, dict):
                    for name, symbol in symbol_table.current_scope.items():
                        symbols.append(self.extract_symbol_info(symbol, 0))
            
            # Ø·Ø±ÙŠÙ‚Ø© 3: Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ attributes Ø§Ù„Ù…Ù…ÙƒÙ†Ø©
            else:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙŠ dictionary ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø±Ù…ÙˆØ²
                for attr_name in dir(symbol_table):
                    if not attr_name.startswith('_'):
                        attr = getattr(symbol_table, attr_name, None)
                        if isinstance(attr, dict) and attr:
                            # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ø°Ø§ dictionary ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø±Ù…ÙˆØ²
                            for key, value in attr.items():
                                if hasattr(value, 'name') or hasattr(value, 'symbol_type'):
                                    symbols.append(self.extract_symbol_info(value, 0))
                        elif isinstance(attr, list) and attr:
                            # Ù‚Ø¯ ØªÙƒÙˆÙ† scopes ÙÙŠ list
                            for scope in attr:
                                if isinstance(scope, dict):
                                    for name, symbol in scope.items():
                                        symbols.append(self.extract_symbol_info(symbol, 0))
            
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø£ÙŠ Ø±Ù…ÙˆØ²ØŒ Ù†Ø­Ø§ÙˆÙ„ Ø·Ø±ÙŠÙ‚Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
            if not symbols:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ø£ÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø¹Ø±ÙØ©
                if hasattr(symbol_table, '__dict__'):
                    for key, value in symbol_table.__dict__.items():
                        if isinstance(value, dict):
                            for name, sym in value.items():
                                if hasattr(sym, 'name'):
                                    symbols.append(self.extract_symbol_info(sym, 0))
        
        except Exception as e:
            # ÙÙŠ Ø­Ø§Ù„Ø© Ø­Ø¯ÙˆØ« Ø®Ø·Ø£ØŒ Ù†Ø±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ© Ù…Ø¹ Ø±Ø³Ø§Ù„Ø©
            print(f"ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø±Ù…ÙˆØ² Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ - {str(e)}")
        
        return symbols
    
    def extract_symbol_info(self, symbol, scope_level=0):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø±Ù…Ø² Ø¨Ø´ÙƒÙ„ Ù…ÙØµÙ„"""
        try:
            symbol_info = {
                'name': getattr(symbol, 'name', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'),
                'type': getattr(symbol, 'symbol_type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
                'data_type': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
                'value': '-',
                'scope': f"Ø§Ù„Ù†Ø·Ø§Ù‚ {scope_level}",
                'is_constant': getattr(symbol, 'is_constant', False),
                'line': getattr(symbol, 'line', '-'),
                'details': ''
            }
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if hasattr(symbol, 'data_type'):
                dt = symbol.data_type
                if dt is not None:
                    if hasattr(dt, 'base_type'):
                        symbol_info['data_type'] = str(dt.base_type)
                        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø¹Ù† Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…Ø±ÙƒØ¨
                        if hasattr(dt, 'is_list') and dt.is_list:
                            symbol_info['details'] = f"Ù‚Ø§Ø¦Ù…Ø©[{dt.list_size}]"
                        elif hasattr(dt, 'is_record') and dt.is_record:
                            symbol_info['details'] = f"Ø³Ø¬Ù„ ({len(dt.fields)} Ø­Ù‚ÙˆÙ„)"
                    else:
                        symbol_info['data_type'] = str(dt)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙŠÙ…Ø©
            if hasattr(symbol, 'value') and symbol.value is not None:
                val = symbol.value
                if isinstance(val, str):
                    symbol_info['value'] = f"'{val}'"
                else:
                    symbol_info['value'] = str(val)
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª
            if hasattr(symbol, 'params') and symbol.params:
                param_count = len(symbol.params)
                symbol_info['value'] = f"({param_count} Ù…Ø¹Ø§Ù…Ù„)"
                # ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
                param_details = []
                for param in symbol.params:
                    if hasattr(param, 'name') and hasattr(param, 'data_type'):
                        param_details.append(f"{param.name}: {param.data_type}")
                if param_details:
                    symbol_info['details'] = ", ".join(param_details)
            
            return symbol_info
            
        except Exception as e:
            return {
                'name': 'Ø®Ø·Ø£',
                'type': 'Ø®Ø·Ø£',
                'data_type': str(e),
                'value': '-',
                'scope': f"Ø§Ù„Ù†Ø·Ø§Ù‚ {scope_level}",
                'is_constant': False,
                'line': '-',
                'details': ''
            }
    
    def generate_code(self, source_code):
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯ - Code Generation"""
        try:
            # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ø£ÙˆÙ„Ø§Ù‹
            semantic_result = self.analyze_semantic(source_code)
            
            if not semantic_result['success']:
                return {
                    'success': False,
                    'code': None,
                    'errors': semantic_result['errors']
                }
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯
            self.generator = CodeGenerator()
            self.python_code = self.generator.generate(self.ast)
            
            return {
                'success': True,
                'code': self.python_code,
                'errors': []
            }
            
        except Exception as e:
            return {
                'success': False,
                'code': None,
                'error': str(e)
            }
    
    def full_analysis(self, source_code):
        """ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø±Ø§Ø­Ù„"""
        results = {
            'lexical': self.analyze_lexical(source_code),
            'syntax': self.analyze_syntax(source_code),
            'semantic': self.analyze_semantic(source_code),
            'code_gen': self.generate_code(source_code)
        }
        return results


# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
def get_lexical_analysis(source_code):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø¬Ù…ÙŠ"""
    analyzer = CompilerAnalyzer()
    return analyzer.analyze_lexical(source_code)


def get_syntax_analysis(source_code):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ"""
    analyzer = CompilerAnalyzer()
    return analyzer.analyze_syntax(source_code)


def get_semantic_analysis(source_code):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ"""
    analyzer = CompilerAnalyzer()
    return analyzer.analyze_semantic(source_code)


def get_symbol_table(source_code):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø±Ù…ÙˆØ²"""
    analyzer = CompilerAnalyzer()
    semantic_result = analyzer.analyze_semantic(source_code)
    return semantic_result.get('symbol_table', [])


def generate_intermediate_code(source_code):
    """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙˆØ³ÙŠØ·"""
    analyzer = CompilerAnalyzer()
    return analyzer.generate_code(source_code)
